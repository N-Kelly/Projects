{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\njkel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\njkel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'public': 0.05555555555555555, 'European': 0.05555555555555555, 'Bank': 0.05555555555555555, 'price': 0.1111111111111111, 'emirate': 0.05555555555555555, 'overseas': 0.05555555555555555, 'newspaper': 0.05555555555555555, 'company': 0.16666666666666666, 'Turkish': 0.05555555555555555, 'increase': 0.05555555555555555, 'options': 0.05555555555555555, 'Higher': 0.05555555555555555, 'pound': 0.05555555555555555, 'Italian': 0.05555555555555555, 'time': 0.05555555555555555}\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "\n",
    "# Creating simple model\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in reuters.sents():\n",
    "    for word1, word2, word3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[(word1, word2)][word3] += 1\n",
    "for word1_word2 in model:\n",
    "    count = float(sum(model[word1_word2].values()))\n",
    "    for word3 in model[word1_word2]:\n",
    "        model[word1_word2][word3] /= count\n",
    "print(dict(model['today', 'the']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today the European Community farm ministers features a plan for a second master limited partnership interests in Saskatchewan .\n"
     ]
    }
   ],
   "source": [
    "# Testing model\n",
    "import random\n",
    "sentence = ['today','the']\n",
    "\n",
    "sentence_finished = False\n",
    "\n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    #r = 0.2\n",
    "    accum = .0\n",
    "    for word in model[tuple(sentence[-2:])].keys():\n",
    "        accum += model[tuple(sentence[-2:])][word]\n",
    "        if accum >= r:\n",
    "            sentence.append(word)\n",
    "            break\n",
    "    if sentence[-2:] == [None, None]:\n",
    "        sentence_finished = True\n",
    "\n",
    "print(' '.join([t for t in sentence if t]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Now Taking into account last 3 words - fourgram model\n",
    "from nltk.util import everygrams\n",
    "model_2= defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sentence in reuters.sents():\n",
    "    my_list = list(everygrams(sentence))\n",
    "    fourgrams = []\n",
    "    for k in my_list:\n",
    "        if len(k) == 4:\n",
    "            fourgrams.append(k)\n",
    "        else:\n",
    "            pass\n",
    "    for words in fourgrams:\n",
    "        word1, word2, word3, word4= words\n",
    "        model_2[(word1, word2, word3)][word4] += 1\n",
    "for word1_word2_word3 in model:\n",
    "    count = float(sum(model_2[word1_word2_word3].values()))\n",
    "    for word4 in model_2[word1_word2_word3]:\n",
    "        model_2[word1_word2_word3][word4] /= count\n",
    "print(dict(model_2['today', 'the', 'price']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today the price of platinum will be substantially higher than that\n"
     ]
    }
   ],
   "source": [
    "# Testing model_2\n",
    "import random\n",
    "sentence = ['today','the', 'price']\n",
    "\n",
    "sentence_finished = False\n",
    "\n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    #r = 0.2\n",
    "    accum = .0\n",
    "    for word in model_2[tuple(sentence[-3:])].keys():\n",
    "        accum += model_2[tuple(sentence[-3:])][word]\n",
    "        if accum >= r:\n",
    "            sentence.append(word)\n",
    "            break\n",
    "    if sentence[-3:] == [None, None, None]:\n",
    "        sentence_finished = True\n",
    "    if len(sentence) > 10:\n",
    "        sentence_finished = True\n",
    "\n",
    "print(' '.join([t for t in sentence if t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentences in the fourgram model seem to usually be more coherent than in the Trigram model. However, the run time was much higher and without the added limit of the length of the sentence, the code runtime becomes huge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
